{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Iterating computations\n",
    "subtitle: I have a generative function with a single variable but 2000 observations, or I just want to use/apply it repeatedly. What do I do?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import genjax\n",
    "from genjax import bernoulli, gen, pretty\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First start by creating a simple generative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def double_flip(p, q):\n",
    "    v1 = bernoulli(p) @ \"v1\"\n",
    "    v2 = bernoulli(q) @ \"v2\"\n",
    "    return v1 + v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we can create a vectorized version that takes a batch of p values and calls the function for each value in the batch. The `in_axes` tell the `vmap` combinator which arguments are mapped over, and which are not. The value `0` means we will map over this argument and `None` means we will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_double_flip = double_flip.vmap(in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the batched version to generate a batch of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To do so, we have to create batched keys and p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "p = jax.random.uniform(subkey, (size_of_batch,))\n",
    "q = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the generative function once for (p1, q), once for (p2, q), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "traces = batched_double_flip.simulate(subkey, (p, q))\n",
    "traces.get_retval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use call it on `(p1, q1)`, `(p2, q2)`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "p = jax.random.uniform(subkey, (size_of_batch,))\n",
    "key, subkey = jax.random.split(key)\n",
    "q = jax.random.uniform(subkey, (size_of_batch,))\n",
    "batched_double_flip_v2 = double_flip.vmap(in_axes=(0, 0))\n",
    "key, subkey = jax.random.split(key)\n",
    "traces = batched_double_flip_v2.simulate(subkey, (p, q))\n",
    "traces.get_retval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We cannot batch different variables with different shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    key, subkey = jax.random.split(key)\n",
    "    p = jax.random.uniform(subkey, (size_of_batch,))\n",
    "    key, subkey = jax.random.split(key)\n",
    "    q = jax.random.uniform(subkey, (size_of_batch + 1,))\n",
    "    key, subkey = jax.random.split(key)\n",
    "    traces = batched_double_flip_v2.simulate(subkey, (p, q))\n",
    "    print(traces.get_retval())\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about iterating `vmap`, e.g. if we want to apply a generative function acting on a pixel over a 2D space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = jnp.zeros([300, 500], dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a function on one \"pixel\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def sample_pixel(pixel):\n",
    "    new_pixel = genjax.normal(pixel, 1.0) @ \"new_pixel\"\n",
    "    return new_pixel\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "tr = sample_pixel.simulate(subkey, (0.0,))\n",
    "tr.get_sample()[\"new_pixel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we want to apply a generative function over a 2D space?\n",
    "\n",
    "We can use a nested `vmap` combinator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = sample_pixel.vmap(in_axes=(0,)).vmap(in_axes=(0,))\n",
    "key, subkey = jax.random.split(key)\n",
    "tr = sample_image.simulate(subkey, (image,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the new_pixel value for each pixel in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    tr.get_sample(),\n",
    "    tr.get_sample()[0, 0, \"new_pixel\"],\n",
    "    tr.get_sample()[299, 499, \"new_pixel\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap this model in a bigger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = jnp.zeros([2, 3], dtype=jnp.float32)\n",
    "\n",
    "\n",
    "@gen\n",
    "def model(p):\n",
    "    sampled_image = sample_image(image) @ \"sampled_image\"\n",
    "    return sampled_image[0] + p\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "tr = model.simulate(subkey, (0.0,))\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ellipsis to access the new_pixel value for each pixel in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.get_sample()[\"sampled_image\", ..., ..., \"new_pixel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can flatten the 2 dimensions into one and use a single `vmap` combinator.\n",
    "This can be more efficient in some cases and usually has a faster compile time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_flat = sample_pixel.vmap(in_axes=(0,))\n",
    "key, subkey = jax.random.split(key)\n",
    "tr = sample_image_flat.simulate(subkey, (image.flatten(),))\n",
    "# resize the sample to the original shape\n",
    "out_image = tr.get_sample()[..., \"new_pixel\"].reshape(image.shape)\n",
    "out_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh but my iteration is actually over time, not space, i.e. I may want to reuse the same model by composing it with itself, e.g. for a Hidden Markov Model (HMM). \n",
    "\n",
    "For this, we can use the `scan` combinator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def hmm_kernel(x):\n",
    "    z = genjax.normal(x, 1.0) @ \"z\"\n",
    "    y = genjax.normal(z, 1.0) @ \"y\"\n",
    "    return y\n",
    "\n",
    "\n",
    "@genjax.scan(n=10)\n",
    "@gen\n",
    "def hmm(x, _):\n",
    "    x1 = hmm_kernel(x) @ \"x1\"\n",
    "    return x1, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "initial_x = 0.0\n",
    "tr_1 = hmm.simulate(subkey, (initial_x, None))\n",
    "print(\"Value of z at the beginning:\")\n",
    "tr_1.get_sample()[0, \"x1\", \"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Value of y at the end:\")\n",
    "tr_1.get_sample()[9, \"x1\", \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_1.get_sample()[..., \"x1\", \"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can directly create the same HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@genjax.scan(n=10)\n",
    "@gen\n",
    "def hmm_v2(x, _):\n",
    "    z = genjax.normal(x, 1.0) @ \"z\"\n",
    "    y = genjax.normal(z, 1.0) @ \"y\"\n",
    "    return y, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the second version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "tr_2 = hmm_v2.simulate(subkey, (initial_x, None))\n",
    "tr_2.get_sample()[0, \"z\"], tr_2.get_sample()[9, \"y\"], tr_2.get_sample()[..., \"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another alternative, we can call the generative function with a `repeat` combinator.\n",
    "This will run the generative function multiple times on a single argument and return the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@genjax.gen\n",
    "def model(y):\n",
    "    x = genjax.normal(y, 0.01) @ \"x\"\n",
    "    y = genjax.normal(x, 0.01) @ \"y\"\n",
    "    return y\n",
    "\n",
    "\n",
    "arg = 3.0\n",
    "key, subkey = jax.random.split(key)\n",
    "tr = model.repeat(n=10).simulate(subkey, (arg,))\n",
    "\n",
    "tr.get_sample()[..., \"x\"], tr.get_retval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can for instance be combined with JAX's `vmap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, 3)\n",
    "args = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "n = 3\n",
    "tr = jax.jit(jax.vmap(model.repeat(n=n).simulate, in_axes=(0, None)))(keys, (args,))\n",
    "tr.get_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it's running a computation |keys| * |args| * |n| times, i.e. 45 times in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.get_retval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genjax-trials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
